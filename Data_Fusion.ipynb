{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for Fusion and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model\n",
    "\n",
    "# Visualization\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical Datasets\n",
    "African = pd.read_csv(r\"/Users/mohammedbasem/Desktop/T2D-Prediction-System--Data-Fusion-for-Enhanced-Decision-Making/processed_datasets/clinical/African_pro.csv\")\n",
    "Bangladesh = pd.read_csv(r\"/Users/mohammedbasem/Desktop/T2D-Prediction-System--Data-Fusion-for-Enhanced-Decision-Making/processed_datasets/clinical/Bangladesh_pro.csv\")\n",
    "Iraq = pd.read_csv(r\"/Users/mohammedbasem/Desktop/T2D-Prediction-System--Data-Fusion-for-Enhanced-Decision-Making/processed_datasets/clinical/Iraq_pro.csv\")\n",
    "\n",
    "# Genetic Datasets\n",
    "inter_genetic = pd.read_pickle(r\"/Users/mohammedbasem/Desktop/T2D-Prediction-System--Data-Fusion-for-Enhanced-Decision-Making/processed_datasets/genetic/inter_genetic_dataset.csv\")\n",
    "normal_genetic = pd.read_pickle(r\"/Users/mohammedbasem/Desktop/T2D-Prediction-System--Data-Fusion-for-Enhanced-Decision-Making/processed_datasets/genetic/normal_genetic_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Target Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Cholesterol', 'Glucose', 'HDL Chol', 'Chol/HDL ratio', 'Age', 'Gender',\n",
      "       'Height', 'Weight', 'BMI', 'Systolic BP', 'Diastolic BP', 'waist',\n",
      "       'hip', 'Waist/hip ratio', 'Diabetes', 'BMI Category'],\n",
      "      dtype='object') \n",
      "\n",
      "Index(['age', 'pulse_rate', 'systolic_bp', 'diastolic_bp', 'glucose', 'height',\n",
      "       'weight', 'bmi', 'family_diabetes', 'hypertensive',\n",
      "       'family_hypertension', 'cardiovascular_disease', 'stroke',\n",
      "       'gender_Encoded', 'diabetic_Encoded'],\n",
      "      dtype='object') \n",
      "\n",
      "Index(['Age', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI',\n",
      "       'Gender_Encoded', 'Class_Encoded'],\n",
      "      dtype='object') \n",
      "\n",
      "Index(['STUDY', 'DISEASE_DESCRIPTION', 'REGION', 'CHR_ID', 'CHR_POS',\n",
      "       'MAPPED_GENE', 'UPSTREAM_GENE_ID', 'DOWNSTREAM_GENE_ID',\n",
      "       'UPSTREAM_GENE_DISTANCE', 'DOWNSTREAM_GENE_DISTANCE', 'SNPS', 'MERGED',\n",
      "       'GENOMIC_CONTEXT', 'INTERGENIC', 'RISK_ALLELE_FREQUENCY', 'PVALUE',\n",
      "       'PVALUE_MLOG', 'EFFECT_SIZE', 'CASE_PERCENTAGE', 'CI_LOWER_BOUND',\n",
      "       'CI_UPPER_BOUND', 'CI_RANGE', 'SNPS_PASSING_QC', 'PLATFORM_AFFYMETRIX',\n",
      "       'PLATFORM_AFFYMETRIX_ILLUMINA', 'PLATFORM_ILLUMINA', 'IMPUTED_ENCODED',\n",
      "       'RISK_ALLELE_ENCODED'],\n",
      "      dtype='object') \n",
      "\n",
      "Index(['STUDY', 'DISEASE_DESCRIPTION', 'REGION', 'CHR_ID', 'CHR_POS',\n",
      "       'MAPPED_GENE', 'SNP_GENE_IDS', 'SNPS', 'MERGED', 'GENOMIC_CONTEXT',\n",
      "       'INTERGENIC', 'RISK_ALLELE_FREQUENCY', 'PVALUE', 'PVALUE_MLOG',\n",
      "       'EFFECT_SIZE', 'CASE_PERCENTAGE', 'CI_LOWER_BOUND', 'CI_UPPER_BOUND',\n",
      "       'CI_RANGE', 'SNPS_PASSING_QC', 'PLATFORM_AFFYMETRIX',\n",
      "       'PLATFORM_AFFYMETRIX_ILLUMINA', 'PLATFORM_ILLUMINA', 'IMPUTED_ENCODED',\n",
      "       'RISK_ALLELE_ENCODED'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(African.columns, \"\\n\")\n",
    "print(Bangladesh.columns, \"\\n\")\n",
    "print(Iraq.columns, \"\\n\")\n",
    "print(inter_genetic.columns, \"\\n\")\n",
    "print(normal_genetic.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniting Target Columns' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "African.rename(columns={\n",
    "    'Diabetes': 'T2D',\n",
    "}, inplace=True)\n",
    " \n",
    "Bangladesh.rename(columns={\n",
    "    'diabetic_Encoded': 'T2D',\n",
    "}, inplace=True)\n",
    " \n",
    "Iraq.rename(columns={\n",
    "    'Class_Encoded': 'T2D',\n",
    "}, inplace=True)\n",
    " \n",
    "# Add a new column 'T2D' with all values set to 1\n",
    "inter_genetic['T2D'] = 1\n",
    " \n",
    "# Add a new column 'T2D' with all values set to 1\n",
    "normal_genetic['T2D'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesterol          int64\n",
      "Glucose              int64\n",
      "HDL Chol             int64\n",
      "Chol/HDL ratio     float64\n",
      "Age                  int64\n",
      "Gender               int64\n",
      "Height               int64\n",
      "Weight               int64\n",
      "BMI                float64\n",
      "Systolic BP          int64\n",
      "Diastolic BP         int64\n",
      "waist                int64\n",
      "hip                  int64\n",
      "Waist/hip ratio    float64\n",
      "T2D                  int64\n",
      "BMI Category         int64\n",
      "dtype: object \n",
      "\n",
      "age                         int64\n",
      "pulse_rate                  int64\n",
      "systolic_bp                 int64\n",
      "diastolic_bp                int64\n",
      "glucose                   float64\n",
      "height                    float64\n",
      "weight                    float64\n",
      "bmi                       float64\n",
      "family_diabetes             int64\n",
      "hypertensive                int64\n",
      "family_hypertension         int64\n",
      "cardiovascular_disease      int64\n",
      "stroke                      int64\n",
      "gender_Encoded              int64\n",
      "T2D                         int64\n",
      "dtype: object \n",
      "\n",
      "Age                 int64\n",
      "Urea              float64\n",
      "Cr                  int64\n",
      "HbA1c             float64\n",
      "Chol              float64\n",
      "TG                float64\n",
      "HDL               float64\n",
      "LDL               float64\n",
      "VLDL              float64\n",
      "BMI               float64\n",
      "Gender_Encoded      int64\n",
      "T2D                 int64\n",
      "dtype: object \n",
      "\n",
      "STUDY                            object\n",
      "DISEASE_DESCRIPTION              object\n",
      "REGION                           object\n",
      "CHR_ID                            int64\n",
      "CHR_POS                           int64\n",
      "MAPPED_GENE                      object\n",
      "UPSTREAM_GENE_ID                  Int64\n",
      "DOWNSTREAM_GENE_ID                Int64\n",
      "UPSTREAM_GENE_DISTANCE            Int64\n",
      "DOWNSTREAM_GENE_DISTANCE          Int64\n",
      "SNPS                             object\n",
      "MERGED                            int64\n",
      "GENOMIC_CONTEXT                  object\n",
      "INTERGENIC                        int64\n",
      "RISK_ALLELE_FREQUENCY           float64\n",
      "PVALUE                          float64\n",
      "PVALUE_MLOG                     float64\n",
      "EFFECT_SIZE                     float64\n",
      "CASE_PERCENTAGE                 float64\n",
      "CI_LOWER_BOUND                  float64\n",
      "CI_UPPER_BOUND                  float64\n",
      "CI_RANGE                        float64\n",
      "SNPS_PASSING_QC                   Int64\n",
      "PLATFORM_AFFYMETRIX               int64\n",
      "PLATFORM_AFFYMETRIX_ILLUMINA      int64\n",
      "PLATFORM_ILLUMINA                 int64\n",
      "IMPUTED_ENCODED                   int64\n",
      "RISK_ALLELE_ENCODED               int64\n",
      "T2D                               int64\n",
      "dtype: object \n",
      "\n",
      "STUDY                            object\n",
      "DISEASE_DESCRIPTION              object\n",
      "REGION                           object\n",
      "CHR_ID                            int64\n",
      "CHR_POS                           int64\n",
      "MAPPED_GENE                      object\n",
      "SNP_GENE_IDS                      Int64\n",
      "SNPS                             object\n",
      "MERGED                            int64\n",
      "GENOMIC_CONTEXT                  object\n",
      "INTERGENIC                        int64\n",
      "RISK_ALLELE_FREQUENCY           float64\n",
      "PVALUE                          float64\n",
      "PVALUE_MLOG                     float64\n",
      "EFFECT_SIZE                     float64\n",
      "CASE_PERCENTAGE                 float64\n",
      "CI_LOWER_BOUND                  float64\n",
      "CI_UPPER_BOUND                  float64\n",
      "CI_RANGE                        float64\n",
      "SNPS_PASSING_QC                   Int64\n",
      "PLATFORM_AFFYMETRIX               int64\n",
      "PLATFORM_AFFYMETRIX_ILLUMINA      int64\n",
      "PLATFORM_ILLUMINA                 int64\n",
      "IMPUTED_ENCODED                   int64\n",
      "RISK_ALLELE_ENCODED               int64\n",
      "T2D                               int64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(African.dtypes, '\\n')\n",
    "print(Bangladesh.dtypes, '\\n')\n",
    "print(Iraq.dtypes, '\\n')\n",
    "print(inter_genetic.dtypes, '\\n')\n",
    "print(normal_genetic.dtypes, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting datasets into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting African dataset\n",
    "X_train_african, X_test_african, y_train_african, y_test_african = train_test_split(\n",
    "    African.drop('T2D', axis=1), African['T2D'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Splitting Bangladesh dataset\n",
    "X_train_bangladesh, X_test_bangladesh, y_train_bangladesh, y_test_bangladesh = train_test_split(\n",
    "    Bangladesh.drop('T2D', axis=1), Bangladesh['T2D'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Splitting Iraq dataset\n",
    "X_train_iraq, X_test_iraq, y_train_iraq, y_test_iraq = train_test_split(\n",
    "    Iraq.drop('T2D', axis=1), Iraq['T2D'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Splitting Inter Genetic dataset\n",
    "X_train_inter_genetic, X_test_inter_genetic, y_train_inter_genetic, y_test_inter_genetic = train_test_split(\n",
    "    inter_genetic.drop('T2D', axis=1), inter_genetic['T2D'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Splitting Normal Genetic dataset\n",
    "X_train_normal_genetic, X_test_normal_genetic, y_train_normal_genetic, y_test_normal_genetic = train_test_split(\n",
    "    normal_genetic.drop('T2D', axis=1), normal_genetic['T2D'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Initializing the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Handling non-numeric data by selecting numeric columns only\n",
    "def preprocess_and_scale(X_train, X_test):\n",
    "    # Selecting only numeric columns\n",
    "    X_train_numeric = X_train.select_dtypes(include=[float, int])\n",
    "    X_test_numeric = X_test.select_dtypes(include=[float, int])\n",
    "    \n",
    "    # Scaling numeric features\n",
    "    X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_scaled = scaler.transform(X_test_numeric)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Preprocessing and scaling for African dataset\n",
    "X_train_african_scaled, X_test_african_scaled = preprocess_and_scale(\n",
    "    X_train_african, X_test_african\n",
    ")\n",
    "\n",
    "# Preprocessing and scaling for Bangladesh dataset\n",
    "X_train_bangladesh_scaled, X_test_bangladesh_scaled = preprocess_and_scale(\n",
    "    X_train_bangladesh, X_test_bangladesh\n",
    ")\n",
    "\n",
    "# Preprocessing and scaling for Iraq dataset\n",
    "X_train_iraq_scaled, X_test_iraq_scaled = preprocess_and_scale(\n",
    "    X_train_iraq, X_test_iraq\n",
    ")\n",
    "\n",
    "# Preprocessing and scaling for Inter Genetic dataset\n",
    "X_train_inter_genetic_scaled, X_test_inter_genetic_scaled = preprocess_and_scale(\n",
    "    X_train_inter_genetic, X_test_inter_genetic\n",
    ")\n",
    "\n",
    "# Preprocessing and scaling for Normal Genetic dataset\n",
    "X_train_normal_genetic_scaled, X_test_normal_genetic_scaled = preprocess_and_scale(\n",
    "    X_train_normal_genetic, X_test_normal_genetic\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "African Dataset Model Selection Results:\n",
      "Logistic Regression: Accuracy = 0.9103\n",
      "Random Forest: Accuracy = 0.8974\n",
      "SVM: Accuracy = 0.8974\n",
      "KNN: Accuracy = 0.8462\n",
      "Gradient Boosting: Accuracy = 0.8846\n",
      "Naive Bayes: Accuracy = 0.8974\n",
      "Decision Tree: Accuracy = 0.8718\n",
      "XGBoost: Accuracy = 0.9231\n",
      "\n",
      "Bangladesh Dataset Model Selection Results:\n",
      "Logistic Regression: Accuracy = 0.9384\n",
      "Random Forest: Accuracy = 0.9430\n",
      "SVM: Accuracy = 0.9403\n",
      "KNN: Accuracy = 0.9347\n",
      "Gradient Boosting: Accuracy = 0.9412\n",
      "Naive Bayes: Accuracy = 0.9053\n",
      "Decision Tree: Accuracy = 0.9127\n",
      "XGBoost: Accuracy = 0.9393\n",
      "\n",
      "Iraq Dataset Model Selection Results:\n",
      "Logistic Regression: Accuracy = 0.9810\n",
      "Random Forest: Accuracy = 0.9684\n",
      "SVM: Accuracy = 0.9684\n",
      "KNN: Accuracy = 0.9494\n",
      "Gradient Boosting: Accuracy = 0.9747\n",
      "Naive Bayes: Accuracy = 0.9620\n",
      "Decision Tree: Accuracy = 0.9747\n",
      "XGBoost: Accuracy = 0.9747\n",
      "\n",
      "Inter Genetic Dataset Model Selection Results:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 37\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)  \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)  \u001b[38;5;66;03m# Predicting on the test set\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)  \u001b[38;5;66;03m# Calculating accuracy\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries for model selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Defining datasets and corresponding scaled data\n",
    "datasets = {\n",
    "    \"African\": (X_train_african_scaled, X_test_african_scaled, y_train_african, y_test_african),\n",
    "    \"Bangladesh\": (X_train_bangladesh_scaled, X_test_bangladesh_scaled, y_train_bangladesh, y_test_bangladesh),\n",
    "    \"Iraq\": (X_train_iraq_scaled, X_test_iraq_scaled, y_train_iraq, y_test_iraq),\n",
    "    \"Inter Genetic\": (X_train_inter_genetic_scaled, X_test_inter_genetic_scaled, y_train_inter_genetic, y_test_inter_genetic),\n",
    "    \"Normal Genetic\": (X_train_normal_genetic_scaled, X_test_normal_genetic_scaled, y_train_normal_genetic, y_test_normal_genetic)\n",
    "}\n",
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "}\n",
    "\n",
    "# Looping through each dataset and evaluating models\n",
    "for dataset_name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    print(f\"\\n{dataset_name} Dataset Model Selection Results:\")\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)  # Training the model\n",
    "        y_pred = model.predict(X_test)  # Predicting on the test set\n",
    "        accuracy = accuracy_score(y_test, y_pred)  # Calculating accuracy\n",
    "        results[model_name] = accuracy\n",
    "\n",
    "    # Displaying results for the current dataset\n",
    "    for model_name, accuracy in results.items():\n",
    "        print(f\"{model_name}: Accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
